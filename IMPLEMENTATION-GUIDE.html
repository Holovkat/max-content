<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Building an AI-Powered Content Repurposing Engine: The Max Content Complete Guide</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Helvetica Neue', sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: #fafafa;
        }
        article {
            background: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        h1 {
            font-size: 2.5em;
            font-weight: 700;
            margin-bottom: 0.3em;
            color: #111;
            line-height: 1.2;
        }
        .subtitle {
            font-size: 1.2em;
            color: #666;
            margin-bottom: 2em;
        }
        h2 {
            font-size: 1.8em;
            margin-top: 2em;
            margin-bottom: 0.8em;
            padding-bottom: 0.3em;
            border-bottom: 2px solid #667eea;
            color: #222;
        }
        h3 {
            font-size: 1.4em;
            margin-top: 1.8em;
            margin-bottom: 0.6em;
            color: #333;
        }
        h4 {
            font-size: 1.1em;
            margin-top: 1.2em;
            margin-bottom: 0.4em;
            color: #444;
        }
        p {
            margin-bottom: 1.2em;
        }
        .lead {
            font-size: 1.1em;
            color: #444;
            margin-bottom: 1.5em;
            padding: 1em;
            background: #f8f9ff;
            border-left: 4px solid #667eea;
            border-radius: 4px;
        }
        .highlight-box {
            background: #fff8e6;
            border: 1px solid #ffd43b;
            padding: 1em;
            margin: 1.5em 0;
            border-radius: 4px;
        }
        .warning-box {
            background: #fff2f2;
            border: 1px solid #ff6b6b;
            padding: 1em;
            margin: 1.5em 0;
            border-radius: 4px;
        }
        .code-block {
            background: #1e1e1e;
            color: #d4d4d4;
            padding: 1.2em;
            border-radius: 6px;
            overflow-x: auto;
            margin: 1.2em 0;
            font-family: 'Monaco', 'Consolas', monospace;
            font-size: 0.9em;
            line-height: 1.5;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5em 0;
            font-size: 0.95em;
        }
        th {
            background: #667eea;
            color: white;
            padding: 12px 8px;
            text-align: left;
            font-weight: 600;
        }
        td {
            padding: 10px 8px;
            border-bottom: 1px solid #ddd;
        }
        tr:nth-child(even) {
            background: #f9f9f9;
        }
        ul, ol {
            margin: 1em 0;
            padding-left: 2em;
        }
        li {
            margin-bottom: 0.6em;
        }
        .callout {
            background: #e3f2fd;
            border: 1px solid #2196f3;
            padding: 1em;
            margin: 1.5em 0;
            border-radius: 4px;
            font-size: 0.95em;
        }
        .meta {
            color: #666;
            font-size: 0.9em;
            margin-bottom: 2em;
            padding-bottom: 1em;
            border-bottom: 1px solid #eee;
        }
        .checklist li {
            list-style-type: none;
            position: relative;
            padding-left: 2em;
        }
        .checklist li:before {
            content: "‚òê";
            position: absolute;
            left: 0;
            font-size: 1.2em;
            color: #667eea;
        }
        .author-box {
            background: #f5f5f5;
            padding: 1em;
            border-radius: 4px;
            margin: 2em 0;
        }
        a {
            color: #667eea;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        .flow-diagram {
            background: #f8f9fa;
            padding: 1em;
            border-radius: 4px;
            font-family: monospace;
            margin: 1.5em 0;
            line-height: 1.4;
        }
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            article {
                padding: 20px;
            }
            h1 {
                font-size: 2em;
            }
            h2 {
                font-size: 1.5em;
            }
        }
    </style>
</head>
<body>
    <article>
        <h1>Building an AI-Powered Content Repurposing Engine: The Max Content Complete Guide</h1>
        <p class="subtitle">Transform single video transcripts into 9+ platform-ready social posts with zero AI slop and human editorial control</p>
        
        <div class="meta">
            <strong>Reading Time:</strong> 25 minutes | <strong>Difficulty:</strong> Intermediate | <strong>Stack:</strong> n8n + Google Gemini + Node.js
        </div>

        <div class="lead">
            <p><em>Content creators face a brutal truth: long-form content gets uploaded once but needs to be recycled endlessly to reach different audiences. Manual repurposing is tedious, inconsistent, and prevents rapid iteration. Max Content solves this by automating the entire workflow with intelligent AI while maintaining magazine-quality editorial standards.</em></p>
        </div>

        <h2>Table of Contents</h2>
        <ol>
            <li><a href="#problem">The Problem: Content Death by a Thousand Cuts</a></li>
            <li><a href="#solution">The Solution: One Input, Nine Outputs</a></li>
            <li><a href="#architecture">Architecture: How It All Fits Together</a></li>
            <li><a href="#prerequisites">What You'll Need</a></li>
            <li><a href="#setup">Step-by-Step Implementation</a></li>
            <li><a href="#voice">Voice DNA: Why This Isn't Generic AI Slop</a></li>
            <li><a href="#payload">Payload Encoding: The Pipe-Delimited Trick</a></li>
            <li><a href="#troubleshooting">Common Issues & Fixes</a></li>
            <li><a href="#enhancements">Advanced: Multi-Model and Quality Gates</a></li>
        </ol>

        <h2 id="problem">The Problem: Content Death by a Thousand Cuts</h2>
        
        <p>Picture this: You spend hours creating an insightful 45-minute YouTube video about building AI agents. The content is gold‚Äîspecific examples, frameworks, numbers. You hit publish, wait for the algorithm to work its magic, and accept that your 45-minute investment will generate views for 48 hours, then fade into obscurity.</p>
        
        <p>But that video contains at least <strong>15 pieces of standalone wisdom</strong> that could reach different audiences:</p>
        
        <ul>
            <li>A contrarian Twitter thread: "Most people misunderstand AI agents..."</li>
            <li>A tactical LinkedIn post: "Here's the exact process I used to automate my sales pipeline"</li>
            <li>A story-driven newsletter: "How I lost $10K by not doing this one thing"</li>
            <li>Instagram captions that spark discussion</li>
        </ul>
        
        <p>Manually extracting these, rewriting for each platform, and maintaining consistent quality takes <strong>3-4 hours per video</strong>. Most creators simply don't do it consistently. The result? Valuable insights reach only a fraction of potential audiences.</p>

        <p>Even worse, generic AI tools produce bland, robotic content that reads like every other motivational post on LinkedIn:</p>
        
        <div class="warning-box">
            <strong>‚ùå Generic AI Slop Output:</strong> "In today's rapidly evolving digital landscape, AI agents are revolutionizing business operations. Entrepreneurs must embrace this paradigm shift to remain competitive. #innovation #AI #future"
        </div>

        <h2 id="solution">The Solution: One Input, Nine Outputs</h2>
        
        <div class="highlight-box">
            <strong>Max Value:</strong> One transcript ‚Üí 9+ platform-specific posts (5 tweets, 3 LinkedIn, 1 newsletter, plus Instagram/Skool) ready to publish with editorial oversight
        </div>

        <p>Max Content is a complete automation pipeline that repurposes long-form content into platform-ready posts while maintaining human editorial control and magazine-quality writing standards.</p>

        <h3>Core Flow</h3>

        <div class="flow-diagram">
YouTube Transcript
       ‚Üì
Content Generator Workflow
  ‚Ä¢ Parse input
  ‚Ä¢ 1x Gemini call produces ALL content
  ‚Ä¢ Build interactive HTML preview
       ‚Üì
Preview Page (Human Review)
  ‚Ä¢ See all generated posts
  ‚Ä¢ Review for quality
  ‚Ä¢ Click "Approve and Post"
       ‚Üì
Content Approval Workflow
  ‚Ä¢ Auto-posts to X/Twitter
  ‚Ä¢ Auto-posts to LinkedIn
  ‚Ä¢ Sends newsletter via email
  ‚Ä¢ Returns confirmation page
        </div>

        <h3>What You'll Walk Away With</h3>

        <ul>
            <li><strong>X/Twitter:</strong> 5 tweets (contrarian, tactical, framework, observations)</li>
            <li><strong>LinkedIn:</strong> 3 posts (deep lesson, framework breakdown, story-driven)</li>
            <li><strong>Newsletter:</strong> 400-600 word email section with actionable takeaways</li>
            <li><strong>Instagram:</strong> Emotionally-driven captions with hooks and calls-to-action</li>
            <li><strong>Skool:</strong> Community discussion starters</li>
        </ul>

        <h2 id="architecture">Architecture: How It All Fits Together</h2>

        <h3>The Two Workflows</h3>

        <h4>1. Content Generator (<code>content-generator.json</code>)</h4>

        <p>Five nodes that transform input into preview:</p>

        <table>
            <tr>
                <th>Node</th>
                <th>Purpose</th>
                <th>Key Output</th>
            </tr>
            <tr>
                <td><strong>Content Form Webhook</strong></td>
                <td>Receives form submission with transcript + platform selection</td>
                <td>Structured JSON payload</td>
            </tr>
            <tr>
                <td><strong>Prepare Input</strong></td>
                <td>Generates session ID, organizes platform flags</td>
                <td>Normalized data structure</td>
            </tr>
            <tr>
                <td><strong>Generate Content</strong></td>
                <td>Single Gemini call produces all content simultaneously</td>
                <td>Raw LLM JSON output</td>
            </tr>
            <tr>
                <td><strong>Build Preview Response</strong></td>
                <td>Creates HTML page with all content, encodes payload</td>
                <td>Interactive preview with "Approve and Post" button</td>
            </tr>
            <tr>
                <td><strong>Respond with HTML</strong></td>
                <td>Returns preview to browser</td>
                <td>HTTP 200 with HTML body</td>
            </tr>
        </table>

        <h4>2. Content Approval (<code>content-approval.json</code>)</h4>

        <p>Nine nodes that handle publishing after approval:</p>

        <table>
            <tr>
                <th>Node</th>
                <th>Purpose</th>
                <th>Condition</th>
            </tr>
            <tr>
                <td><strong>Approval Webhook</strong></td>
                <td>Receives encoded payload from button click</td>
                <td>Always triggered</td>
            </tr>
            <tr>
                <td><strong>Decode Payload</strong></td>
                <td>Parses pipe-delimited format, extracts LLM content</td>
                <td>Always</td>
            </tr>
            <tr>
                <td><strong>Post to X/Twitter</strong></td>
                <td>Posts tweets via Twitter API</td>
                <td>If X platform selected</td>
            </tr>
            <tr>
                <td><strong>Post to LinkedIn</strong></td>
                <td>Posts via LinkedIn API</td>
                <td>If LinkedIn platform selected</td>
            </tr>
            <tr>
                <td><strong>Build Email HTML</strong></td>
                <td>Creates Outlook-compatible newsletter template</td>
                <td>If newsletter selected</td>
            </tr>
            <tr>
                <td><strong>Send via Resend</strong></td>
                <td>Calls Resend API to deliver newsletter</td>
                <td>If newsletter selected</td>
            </tr>
        </table>

        <h3>Why Pipe-Delimited Payload?</h3>

        <p>Most workflows use JSON encoding. Max Content uses pipe-delimited format. Here's why:</p>

        <div class="code-block">
// Problem: LLM output contains control characters that break JSON parsing
const badJson = '{"key": "value\x00\x1F"}';  // \x00 = null, \x1F = unit separator

// Solution: Isolate LLM data in separate base64 segment
const payload = [
  sessionId,
  xFlag,
  linkedinFlag,
  recipients,
  base64EncodedLlmText  // LLM data here, safely encoded
].join('|');

// Then base64 encode entire payload
const encodedPayload = Buffer.from(payload).toString('base64');
// Result: sessionId|1|0|user@email.com|eyJrZXlfaWRlYXMi... (base64)
        </div>

        <p><strong>Benefits:</strong></p>
        <ul>
            <li>LLM output with control characters doesn't break parsing</li>
            <li>Simple string split operations (fast)</li>
            <li>Isolates potentially problematic data</li>
            <li>Nest-proof (no JSON-in-JSON fragility)</li>
        </ul>

        <h2 id="prerequisites">What You'll Need</h2>

        <table>
            <tr>
                <th>Component</th>
                <th>Technology</th>
                <th>Cost</th>
                <th>Purpose</th>
            </tr>
            <tr>
                <td><strong>Hosting</strong></td>
                <td>Hostinger VPS (KVM2)</td>
                <td>Free (hackathon) or $5-10/mo</td>
                <td>n8n deployment</td>
            </tr>
            <tr>
                <td><strong>Orchestration</strong></td>
                <td>n8n (self-hosted)</td>
                <td>FREE</td>
                <td>Workflow management</td>
            </tr>
            <tr>
                <td><strong>AI Model</strong></td>
                <td>Google Gemini Flash</td>
                <td>FREE (1M tokens/day)</td>
                <td>Content generation</td>
            </tr>
            <tr>
                <td><strong>Email</strong></td>
                <td>Resend API</td>
                <td>FREE tier, then ~$0.10/email</td>
                <td>Newsletter delivery</td>
            </tr>
            <tr>
                <td><strong>X/Twitter</strong></td>
                <td>OAuth 2.0 API</td>
                <td>FREE</td>
                <td>Auto-posting</td>
            </tr>
            <tr>
                <td><strong>LinkedIn</strong></td>
                <td>OAuth 2.0 API</td>
                <td>FREE</td>
                <td>Auto-posting</td>
            </tr>
        </table>

        <h3>External Accounts Required</h3>

        <ol>
            <li><strong>Google Account</strong> ‚Üí Gemini API key at <a href="https://ai.google.dev">ai.google.dev</a></li>
            <li><strong>Twitter Developer</strong> ‚Üí Create app at <a href="https://developer.twitter.com">developer.twitter.com</a> (takes 1-2 days for approval)</li>
            <li><strong>LinkedIn Developer</strong> ‚Üí Create app at <a href="https://linkedin.com/developers">linkedin.com/developers</a> (instant)</li>
            <li><strong>Resend</strong> ‚Üí Sign up at <a href="https://resend.com">resend.com</a> (free tier available)</li>
        </ol>

        <div class="callout">
            <strong>üí° Pro Tip:</strong> Create all developer accounts in parallel on Day 1. Twitter approval is the slowest (1-2 days), so get that started first.
        </div>

        <h2 id="setup">Step-by-Step Implementation</h2>

        <h3>Phase 1: Infrastructure Setup (30 minutes)</h3>

        <h4>Step 1: Provision VPS</h4>
        <ol>
            <li>Log into Hostinger dashboard</li>
            <li>Navigate to VPS ‚Üí Create Instance</li>
            <li>Select KVM2 plan (4GB RAM recommended)</li>
            <li>Choose Ubuntu 24.04 LTS</li>
            <li>Note the IP address and SSH credentials</li>
        </ol>

        <h4>Step 2: Install n8n</h4>

        <div class="code-block">
# SSH into your VPS
ssh root@YOUR_IP_ADDRESS

# Install Docker if not present
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

# Run n8n container
docker run -it --rm --name n8n -p 5678:5678 \
  -e N8N_BASIC_AUTH_ACTIVE=true \
  -e N8N_BASIC_AUTH_USER=admin \
  -e N8N_BASIC_AUTH_PASSWORD=YOUR_SECURE_PASSWORD \
  -e N8N_HOST=YOUR_IP_ADDRESS \
  -v ~/.n8n:/home/node/.n8n \
  n8nio/n8n
        </div>

        <p>Access n8n at: <code>https://YOUR_IP:5678</code></p>
        <p>Use the credentials you set in the docker command above.</p>

        <h3>Phase 2: Configure Credentials (15 minutes)</h3>

        <h4>Step 3: Google Gemini API</h4>
        <ol>
            <li>Go to <a href="https://ai.google.dev">ai.google.dev</a></li>
            <li>Click "Get API Key" ‚Üí "Create API key"</li>
            <li>Copy the key</li>
            <li>In n8n: Settings ‚Üí Credentials ‚Üí "Add Credential" ‚Üí Search for "Google Gemini"</li>
            <li>Paste your API key</li>
        </ol>

        <h4>Step 4: Twitter OAuth</h4>
        <ol>
            <li>Go to <a href="https://developer.twitter.com">developer.twitter.com</a></li>
            <li>Click "Projects & Apps" ‚Üí "Create Project"</li>
            <li>Fill out the application (describe your use case clearly)</li>
            <li>Wait for approval (1-2 business days)</li>
            <li>Once approved, create an app within your project</li>
            <li>Get Consumer Key and Consumer Secret</li>
            <li>Navigate to "Keys and tokens" ‚Üí generate Access Token and Secret</li>
            <li>In n8n: Settings ‚Üí Credentials ‚Üí "Add Credential" ‚Üí "Twitter OAuth 2.0"</li>
            <li>Paste all four keys, complete OAuth flow</li>
        </ol>

        <h4>Step 5: LinkedIn OAuth</h4>
        <ol>
            <li>Go to <a href="https://linkedin.com/developers">linkedin.com/developers</a></li>
            <li>Click "Create App"</li>
            <li>Provide app name, description, logo</li>
            <li>Add <code>https://YOUR_IP:5678/rest/oauth2-credential/callback</code> as redirect URL</li>
            <li>Copy Client ID and Client Secret</li>
            <li>In n8n: Settings ‚Üí Credentials ‚Üí "Add Credential" ‚Üí "LinkedIn OAuth2"</li>
            <li>Paste credentials, complete OAuth flow</li>
        </ol>

        <h4>Step 6: Resend API</h4>
        <ol>
            <li>Go to <a href="https://resend.com">resend.com</a> and sign up</li>
            <li>Navigate to "API Keys" ‚Üí "Create API Key"</li>
            <li>Copy the key (starts with "re_")</li>
            <li>In n8n: Settings ‚Üí Credentials ‚Üí "Add Credential"</li>
            <li>Search for "HTTP Header Auth" or "Resend"</li>
            <li>Header Name: <code>Authorization</code></li>
            <li>Header Value: <code>Bearer YOUR_RESEND_KEY</code></li>
        </ol>

        <h3>Phase 3: Import Workflows (10 minutes)</h3>

        <h4>Step 7: Get the Workflow Files</h4>

        <div class="code-block">
# On your local machine
git clone https://github.com/your-username/max-content.git
cd max-content/n8n-workflows/
        </div>

        <h4>Step 8: Import Content Generator</h4>
        <ol>
            <li>In n8n, click "Workflows" ‚Üí "Import from File"</li>
            <li>Select <code>content-generator.json</code></li>
            <li>Review the workflow (should show 5 nodes)</li>
            <li>Double-click "Generate Content" node</li>
            <li>Select your Gemini credential from dropdown</li>
            <li>Click "Save"</li>
        </ol>

        <h4>Step 9: Import Content Approval</h4>
        <ol>
            <li>In n8n, click "Workflows" ‚Üí "Import from File"</li>
            <li>Select <code>content-approval.json</code></li>
            <li>Review the workflow (should show 9 nodes)</li>
            <li>Double-click each platform-specific node (Twitter, LinkedIn, Resend)</li>
            <li>Select the appropriate credentials</li>
            <li>Click "Save"</li>
        </ol>

        <h4>Step 10: Activate Both Workflows</h4>
        <ol>
            <li>For each workflow, click the switch in the top-right corner</li>
            <li>They should turn from gray to blue/purple</li>
            <li>Active workflows automatically listen for triggers</li>
        </ol>

        <h3>Phase 4: Test Everything (45 minutes)</h3>

        <h4>Step 11: Test Content Generator</h4>

        <p>Get your webhook URL:</p>
        <ol>
            <li>Open "Content Generator" workflow</li>
            <li>Click "Content Form" trigger node</li>
            <li>In the right panel, scroll to "Test URL"</li>
            <li>Copy the webhook URL (looks like <code>https://YOUR_IP:5678/webhook/YOUR_ID</code>)</li>
        </ol>

        <p>Create a test payload:</p>
        <div class="code-block">
# Create test-data.json
{
  "video_title": "How to Automate E-commerce Support with AI Agents",
  "transcript": "Last month, our support team was drowning in 200+ tickets per day. Most were basic questions about order status, returns, and password resets. We spent $15K on offshore support that got 60% CSAT. Then we built an AI agent in a weekend that handles 85% of volume and increased CSAT to 92%.\n\nThe key insight: don't try to build a perfect bot on day one. Start with the 10 most common utterances. We used LlamaIndex to parse our help docs, built a simple intent classifier, and connected it to Shopify's API. Total cost: $12/month in API calls.\n\nBiggest mistake: we tried to over-automate. The agent crashed when someone said 'I need help finding my package but the tracking number isn't working.' Now we have a human handoff trigger when confidence is below 0.7\n\nFramework: 1) Map 20 most common intents, 2) Build simple decision tree, 3) Add human fallback for edge cases, 4) Measure CSAT weekly, 5) Expand only when you have 95%+ accuracy\n\nWhich metric should I cover next? Reply below and I'll share our exact Python script.",
  "platforms": {
    "x": true,
    "linkedin": true,
    "newsletter": true
  },
  "recipients": "test@example.com",
  "sender_name": "Max Content Team"
}
        </div>

        <p>Send the test:</p>
        <div class="code-block">
curl -X POST "https://YOUR_IP:5678/webhook/YOUR_ID" \
  -H "Content-Type: application/json" \
  -d @test-data.json
        </div>

        <p>Expect response: HTML preview page with all your generated content</p>

        <h4>Step 12: Test Content Approval</h4>

        <p>Once you're satisfied with the preview:</p>
        <ol>
            <li>Click the "Approve and Post" button on the preview page</li>
            <li>Check that all posts appear on your Twitter feed</li>
            <li>Check that LinkedIn posts appear</li>
            <li>Check your email for the newsletter</li>
            <li>Review the confirmation page</li>
        </ol>

        <div class="callout">
            <strong>üí° Debugging Tip:</strong> If posts don't appear, check n8n execution logs (Workflows ‚Üí Executions ‚Üí View details). Common issues: expired OAuth tokens, rate limits, or malformed payloads.
        </div>

        <h2 id="voice">Voice DNA: Why This Isn't Generic AI Slop</h2>

        <p>The difference between useful automation and just more AI-generated noise is <strong>voice calibration</strong> and <strong>editorial principles</strong>.</p>

        <h3>Target Voice: Liam Ottley / Morningside AI</h3>

        <table>
            <tr>
                <th>Dimension</th>
                <th>Characteristic</th>
                <th>Example</th>
            </tr>
            <tr>
                <td><strong>Energy</strong></td>
                <td>High-drive, urgent, building-while-speaking</td>
                <td>"I'm literally building this on my second screen as we talk..."</td>
            </tr>
            <tr>
                <td><strong>Tone</strong></td>
                <td>Direct, practical, transparently ambitious</td>
                <td>"Here's exactly the Python script" (not "Here's a tool that might help")</td>
            </tr>
            <tr>
                <td><strong>Style</strong></td>
                <td>Tutorial-meets-vlog, educational with real numbers</td>
                <td>"We spent $15K. My mistake cost $12K. Here are the metrics that matter..."</td>
            </tr>
        </table>

        <h3>Signature Patterns</h3>

        <div class="highlight-box">
            <strong>‚úÖ Revenue Transparency:</strong> "$100k MRR", "60+ team members", actual business metrics
        </div>

        <div class="highlight-box">
            <strong>‚úÖ Mistake-First Learning:</strong> "I screwed this up so you don't have to"
        </div>

        <div class="highlight-box">
            <strong>‚úÖ Action Orientation:</strong> "Build your first AI agent this weekend" (not "learn about AI agents")
        </div>

        <div class="highlight-box">
            <strong>‚úÖ Framework Thinking:</strong> "The 3-Step Method", "The Reverse-Build Strategy", named methodologies
        </div>

        <div class="highlight-box">
            <strong>‚úÖ No Jargon Gatekeeping:</strong> Explains concepts clearly, defines terms when needed
        </div>

        <h3>Editorial Principles (The Anti-Slop Rules)</h3>

        <table>
            <tr>
                <th>Principle</th>
                <th>Implementation</th>
                <th>Example</th>
            </tr>
            <tr>
                <td><strong>Clarity Before Cleverness</strong></td>
                <td>Simple words, one idea per sentence</td>
                <td>"Let me walk you through exactly what we built" (not "Let's conceptualize the architecture")</td>
            </tr>
            <tr>
                <td><strong>Evidence-Grounded</strong></td>
                <td>Every claim needs a number, name, or moment</td>
                <td>"Our team of 47 engineers" (not "a lot of engineers")</td>
            </tr>
            <tr>
                <td><strong>Hook ‚Üí Value ‚Üí CTA</strong></td>
                <td>Mandatory structure for every piece</td>
                <td>Hook: "Most people get X wrong." Value: [specific framework with numbers]. CTA: "Try step 1 and reply with results."</td>
            </tr>
        </table>

        <h3>Banned Phrases (The AI Slop Hall of Shame)</h3>

        <div class="warning-box">
            <strong>‚ùå Generic Openers That Will Fail Quality Check:</strong>
            <ul>
                <li>"In today's rapidly changing world..."</li>
                <li>"Are you tired of..."</li>
                <li>"The future is here..."</li>
                <li>"AI is revolutionizing..."</li>
                <li>"Picture this: [followed by generic scenario]"</li>
                <li>"I woke up this morning and realized..."</li>
                <li>"The secret to [topic] is..."</li>
            </ul>
        </div>

        <h3>The Unified Prompt Template</h3>

        <p>Here's the actual prompt that generates all content in one shot:</p>

        <div class="code-block">
## SYSTEM PROMPT

You are a senior content strategist at The Atlantic who deeply understands 
AI automation and startups. You have the analytical rigor of a journalist 
combined with the practical mindset of an entrepreneur like Liam Ottley.

## TASK

Analyze the following transcript and produce:

### 1. KEY IDEAS (5-7)
- Core insights that challenge assumptions
- Each backed by evidence from transcript
- Actionable or perspective-shifting

### 2. TWITTER POSTS (exactly 5)
Generate 5 different tweet types:
- Contrarian: "Most people think X. Here's why that's wrong."
- Tactical: "Here's the exact process I use for..."
- Mistake: "I lost $X by not doing this..."
- Framework: "The 3-step method that..."
- Observation: "What nobody tells you about..."

Each must be 200-280 chars, follow Hook‚ÜíValue‚ÜíCTA structure

### 3. LINKEDIN POSTS (exactly 3)
Generate 3 different post types:
- Deep Lesson: Extended insight with full context
- Framework Post: Step-by-step breakdown
- Story Post: Narrative-driven lesson

Each 1200-1800 chars, heavy line breaks, specific numbers/examples

### 4. NEWSLETTER SECTION (exactly 1)
Structure:
- 2-3 sentence opening hook
- 1 paragraph key insight
- 3-5 actionable bullets
- Framework or method
- 2 sentence closing with soft CTA

400-600 words total

### 5. INSTAGRAM CAPTIONS
2-3 emotionally-driven captions with hooks and CTAs

### 6. SKOOL COMMUNITY POST
Community discussion starter with summary, takeaways, engagement question

## VOICE TONE

{{tone}} - {{tone_description}}
Niche: {{niche}}
Target Audience: {{target_audience}}

Voice: Liam Ottley/Morningside AI - direct, practical, numbers-forward

## QUALITY RULES

‚úÖ Specific examples, numbers, moments (not vague advice)
‚úÖ Platform-native voice and length
‚úÖ Hook‚ÜíValue‚ÜíCTA structure on every piece
‚ùå Generic filler ("In today's fast-paced world...")
‚ùå Obvious AI-generated patterns
‚ùå Clickbait that doesn't deliver

## OUTPUT FORMAT

Return ONLY valid JSON (no markdown):

{
  "key_ideas": [{"title": "...", "insight": "...", "evidence": "..."}],
  "tweets": [{"type": "...", "content": "...", "hook_technique": "..."}],
  "linkedin": [{"type": "...", "hook": "...", "body": "...", "cta": "..."}],
  "newsletter": {"subject": "...", "opening": "...", "insight": "...", "takeaways": ["..."], "closing": "..."},
  "instagram": [{"hook": "...", "body": "...", "cta": "..."}],
  "skool": {"title": "...", "intro": "...", "takeaways": ["..."], "question": "..."}
}
        </div>

        <h2 id="payload">Payload Encoding: The Technical Deep Dive</h2>

        <p>The pipe-delimited encoding system is the unsung hero that prevents payload corruption. Here's exactly how it works:</p>

        <h3>Encoding Process (Content Generator)</h3>

        <div class="code-block">
// Step 1: Sanitize LLM output (remove control characters)
const llmOutput = $('Generate Content').first().json;
const sanitizedOutput = JSON.stringify(llmOutput)
  .replace(/[\x00-\x1F\x7F]/g, ' ')  // Remove null, separators, DEL
  .trim();

// Step 2: Base64 encode the LLM text
const base64LlmText = Buffer.from(sanitizedOutput).toString('base64');
// Result: eyJrZXlfaWRlYXMiOlt7InRpdGxlIjoiLi4uIn1dLi4u

// Step 3: Create pipe-delimited array
const platformFlags = {
  x: $('Prepare Input').first().json.platforms.includes('twitter'),
  linkedin: $('Prepare Input').first().json.platforms.includes('linkedin'),
  newsletter: $('Prepare Input').first().json.platforms.includes('newsletter')
};

const payload = [
  sessionId,                    // position 0
  platformFlags.x ? '1' : '0',  // position 1
  platformFlags.linkedin ? '1' : '0',  // position 2
  platformFlags.newsletter ? '1' : '0',  // position 3
  recipients.join(','),        // position 4: comma-separated emails
  senderName,                  // position 5
  base64LlmText                // position 6: the LLM data
].join('|');

// Step 4: Base64 encode entire payload
const encodedPayload = Buffer.from(payload).toString('base64');

// Step 5: Create approval URL
const approvalUrl = 
  `${baseUrl}/webhook/content-approval-confirm?payload=${encodedPayload}`;
        </div>

        <h3>Decoding Process (Content Approval)</h3>

        <div class="code-block">
// Step 1: Extract payload from query string
const encodedPayload = $webhook.query.payload;

// Step 2: Base64 decode outer payload
const decodedPayload = Buffer.from(encodedPayload, 'base64').toString();
// Result: "session-123|1|0|1|user@example.com|Max|eyJrZXlfa..."

// Step 3: Split by pipe
const parts = decodedPayload.split('|');

// Step 4: Extract all fields using positions
const sessionId = parts[0];          // "session-123"
const xFlag = parts[1] === '1';      // true
const linkedinFlag = parts[2] === '1';  // false
const newsletterFlag = parts[3] === '1';  // true
const recipients = parts[4].split(',');  // ["user@example.com"]
const senderName = parts[5];          // "Max"
const base64LlmText = parts[6];       // "eyJrZXlfa..."

// Step 5: Base64 decode and parse LLM JSON
const llmText = Buffer.from(base64LlmText, 'base64').toString();
const llmOutput = JSON.parse(llmText);
// Result: { "key_ideas": [...], "tweets": [...], ... }
        </div>

        <h3>Why This Works</h3>

        <ul>
            <li><strong>Isolates Problem Data:</strong> LLM output (with weird characters) lives in its own base64 segment</li>
            <li><strong>No JSON-in-JSON Nesting:</strong> Avoids double-escaping hell</li>
            <li><strong>Fast String Operations:</strong> Splitting a string by pipe is O(n) and cheap</li>
            <li><strong>Human-Readable:</strong> You can visually inspect base64-decoded payload</li>
            <li><strong>Transport Agnostic:</strong> Works with webhooks, query strings, email links</li>
        </ul>

        <h2 id="troubleshooting">Common Issues & Fixes</h2>

        <h3>Issue 1: "Error: Invalid JSON in LLM output"</h3>

        <div class="warning-box">
            <strong>Symptoms:</strong> Content approval fails at "Decode Payload" step with JSON.parse error
        </div>

        <p><strong>Causes:</strong></p>
        <ul>
            <li>LLM returned markdown code fences (```json ... ```)</li>
            <li>Control characters in LLM text (null bytes, etc.)</li>
            <li>Truncated response (LLM hit max tokens)</li>
        </ul>

        <p><strong>Fix:</strong></p>
        <div class="code-block">
// In Build Preview Response node, add sanitization:
const rawResponse = $('Generate Content').first().json;

// Remove markdown fences
const cleaned = (rawResponse.text || rawResponse.response || '')
  .replace(/```json\n?/g, '')
  .replace(/```\n?/g, '')
  .trim();

// Remove control characters
const sanitized = cleaned.replace(/[\x00-\x1F\x7F]/g, ' ');

// Double-check it's valid JSON
try {
  JSON.parse(sanitized);
} catch (e) {
  throw new Error(`Invalid JSON from LLM: ${e.message}\n\n${sanitized.substring(0, 200)}...`);
}
        </div>

        <h3>Issue 2: "Error posting to Twitter/X: 403 Forbidden"</h3>

        <div class="warning-box">
            <strong>Symptoms:</strong> Content approval workflow fails at "Post to X" node
        </div>

        <p><strong>Causes:</strong></p>
        <ul>
            <li>OAuth token expired (need to refresh credentials in n8n)</li>
            <li>API rate limit exceeded (15 requests per 15 minutes)</li>
            <li>Content violates Twitter policy (duplicates, spam)</li>
            <li>App permissions not set correctly (need "Read and Write")</li>
        </ul>

        <p><strong>Fix:</strong> Check n8n execution logs, re-authorize OAuth, add rate limiting:</p>
        <div class="code-block">
// In Post to X node, add delay to avoid rate limits
const tweets = [...];
for (let i = 0; i < tweets.length; i++) {
  await postTweet(tweets[i]);
  if (i < tweets.length - 1) {
    await new Promise(resolve => setTimeout(resolve, 1000)); // 1 second delay
  }
}
        </div>

        <h3>Issue 3: "Error posting to LinkedIn: Unauthorized"</h3>

        <p><strong>Causes:</strong></p>
        <ul>
            <li>LinkedIn OAuth token expired (n8n auto-refreshes, but might fail)</li>
            <li>App doesn't have "w_member_social" permission</li>
            <li>Trying to post to company page without proper permissions</li>
        </ul>

        <p><strong>Fix:</strong> Re-authorize LinkedIn credential, ensure correct scopes are requested during OAuth flow.</p>

        <h3>Issue 4: Newsletter shows white text on white background (Outlook)</h3>

        <div class="warning-box">
            <strong>Symptoms:</strong> Email looks correct in Gmail, broken in Outlook (white text on white)
        </div>

        <p><strong>Cause:</strong> Outlook doesn't support CSS gradients. The newsletter uses white text on gradient backgrounds.</p>

        <p><strong>Fix:</strong> Replace gradients with solid colors:</p>
        <div class="code-block">
<!-- BEFORE - breaks in Outlook -->
<div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);">
  <p style="color: white;">Text here</p>
</div>

<!-- AFTER - works everywhere -->
<div style="background-color: #667eea;">
  <p style="color: white;">Text here</p>
</div>
        </div>

        <h3>Issue 5: "Error: Cannot read property 'json' of undefined"</h3>

        <p><strong>Causes:</strong></p>
        <ul>
            <li>Previous node didn't execute (conditional execution)</li>
            <li>Node name changed but reference didn't update</li>
            <li>Trying to access data from wrong execution branch</li>
        </ul>

        <p><strong>Fix:</strong> Check that all nodes execute, verify node names match exactly, add defensive checks:</p>
        <div class="code-block">
// Instead of:
const data = $('Generate Content').first().json;

// Use:
const prevNode = $('Generate Content');
if (!prevNode || !prevNode.first()) {
  throw new Error('Generate Content node did not execute or returned empty');
}
const data = prevNode.first().json;
        </div>

        <h2 id="enhancements">Advanced: Multi-Model and Quality Gates</h2>

        <h3>Multi-Model Architecture (Scaling Beyond MVP)</h3>

        <p>The documented spec mentions three AI models working together:</p>

        <div class="flow-diagram">
Input Transcript
       ‚Üì
[ GLM-4 + Kimi-K2 ] ‚Üí Generate initial content (parallel)
       ‚Üì
[ Gemini Flash ] ‚Üí Curate and select best outputs
       ‚Üì
[ Gemini Flash ] ‚Üí Critique and score quality
       ‚Üì
[ Human Preview ] ‚Üí Final approval
        </div>

        <p><strong>Benefits of Multi-Model:</strong></p>
        <ul>
            <li><strong>Reduced Bias:</strong> Different models have different strengths/weaknesses</li>
            <li><strong>Higher Quality:</strong> Curator (Gemini) picks best from two generators</li>
            <li><strong>Redundancy:</strong> If one API fails, fallback to single model</li>
        </ul>

        <p><strong>Implementation:</strong> Run GLM-4 and Kimi-K2 in parallel, pass both outputs to Gemini curator node that selects the best version:</p>

        <div class="code-block">
// In Gemini Curator node:
const glmOutput = $('GLM-4 Generator').first().json;
const kimiOutput = $('Kimi-K2 Generator').first().json;

const prompt = `
You are a senior editor. Compare these two content versions and select the better one.

Version A (GLM-4):
${JSON.stringify(glmOutput, null, 2)}

Version B (Kimi-K2):
${JSON.stringify(kimiOutput, null, 2)}

Select the version with:
1. More specific examples and numbers
2. Stronger hook (challenges assumptions)
3. Better Hook‚ÜíValue‚ÜíCTA structure
4. More natural voice/less AI slop

Return ONLY the winning version as valid JSON.
`;

const response = await gemini.generate(prompt);
        </div>

        <h3>Automated Quality Gate (Optional Enhancement)</h3>

        <p>Current MVP uses human preview as quality gate. For true automation, add automated quality scoring:</p>

        <div class="code-block">
// Quality Rubric (1-5 scale per dimension)
const qualityRubric = {
  "hook_clarity": {
    1: "Generic/clickbait",
    2: "Vaguely interesting",
    3: "Interesting but predictable",
    4: "Strong, specific hook",
    5: "Genuine cognitive dissonance challenges assumptions"
  },
  "specificity": {
    1: "All abstract concepts",
    2: "Mostly abstract",
    3: "Some concrete examples",
    4: "Good use of examples/numbers",
    5: "Names, numbers, moments throughout"
  },
  // ... voice_authenticity, value_density, cta_naturalness
};

// Automatic quality check:
const scoredContent = await gemini.critique({
  content: generatedPost,
  rubric: qualityRubric,
  min_score: 16 // Twitter posts need 16/25 to pass
});

if (scoredContent.total_score < 16) {
  // Regenerate with critique feedback
  return regenerateWithFeedback(scoredContent.feedback);
}
        </div>

        <h3>Pass Thresholds by Platform</h3>

        <table>
            <tr>
                <th>Platform</th>
                <th>Min Score (out of 25)</th>
                <th>Regeneration Attempts</th>
            </tr>
            <tr>
                <td>X/Twitter</td>
                <td>16</td>
                <td>2</td>
            </tr>
            <tr>
                <td>LinkedIn</td>
                <td>18</td>
                <td>2</td>
            </tr>
            <tr>
                <td>Newsletter</td>
                <td>20</td>
                <td>1 (too expensive to regenerate 600 words)</td>
            </tr>
        </table>

        <h2>Final Thoughts: Why This Matters</h2>

        <p>Max Content isn't just another automation tool. It's a <strong>content engine</strong> that combines:</p>

        <ul>
            <li><strong>Editorial Standards:</strong> Voice calibration prevents AI slop</li>
            <li><strong>Human Control:</strong> Preview gate ensures quality before publishing</li>
            <li><strong>Platform Expertise:</strong> Each post optimized for specific platform norms</li>
            <li><strong>Technical Robustness:</strong> Pipe-delimited encoding handles real-world edge cases</li>
            <li><strong>Zero Ongoing Cost:</strong> Free tier of Gemini + self-hosted n8n</li>
        </ul>

        <div class="highlight-box">
            <strong>Bottom Line:</strong> A 45-minute video can reach 9x more people across 5 platforms with editorial oversight, maintaining quality while dramatically scaling content reach.
        </div>

        <p>The real magic isn't in the automation‚Äîit's in the <strong>editorial standards that make content worth reading</strong> even when generated by AI.</p>

        <h2>Quick Reference</h2>

        <table>
            <tr>
                <th>Metric</th>
                <th>Value</th>
            </tr>
            <tr>
                <td>Total Setup Time</td>
                <td>2-4 hours (depending on Twitter approval)</td>
            </tr>
            <tr>
                <td>Ongoing Costs</td>
                <td>$0-5/month (newsletter volume dependent)</td>
            </tr>
            <tr>
                <td>Workflow Execution Time</td>
                <td>2-3 minutes end-to-end</td>
            </tr>
            <tr>
                <td>Content Created Per Run</td>
                <td>15+ content pieces (5 tweets, 3 LinkedIn, 1 newsletter, etc.)</td>
            </tr>
            <tr>
                <td>API Calls Per Run</td>
                <td>~13 (1 generation + 12 quality critique if enabled)</td>
            </tr>
            <tr>
                <td>Input Requirements</td>
                <td>Transcript + Video Title (100+ chars recommended)</td>
            </tr>
        </table>

        <h2>Need Help?</h2>

        <p>Common issues and solutions are documented in the <code>AGENTS.md</code> file. If you're stuck:</p>

        <ol>
            <li>Check n8n execution logs for specific error messages</li>
            <li>Verify all credentials are active and not expired</li>
            <li>Test payload generation with simple transcript first</li>
            <li>Inspect HTML output for markup errors</li>
        </ol>

        <div class="author-box">
            <strong>About This Guide</strong><br>
            This implementation guide was created from the <a href="https://github.com/your-username/max-content">Max Content</a> project‚Äîa production-ready content repurposing engine built for the Hostinger x n8n hackathon. All workflows, prompts, and architecture decisions are battle-tested and live in production.
        </div>

        <hr>
        
        <p><em>Now go transform that 45-minute video into 9 pieces of platform-perfect content. Your audience (and your calendar) will thank you.</em></p>
    </article>
</body>
</html>